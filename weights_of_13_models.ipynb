{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from scipy.special import logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная агрегация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordbtch = pd.read_csv('input/wordbatch-fm-ftrl-using-mse-lb-0-9804/lvl0_wordbatch_clean_sub.csv')\n",
    "corrbl = pd.read_csv('input/another-blend-tinkered-by-correlation/corr_blend.csv')\n",
    "grucnn = pd.read_csv('input/bi-gru-cnn-poolings/submission.csv')\n",
    "bilst = pd.read_csv('input/bidirectional-lstm-with-convolution/submission.csv')\n",
    "supbl= pd.read_csv('input/blend-of-blends-1/superblend_1.csv')\n",
    "lgbm = pd.read_csv('input/lgbm-with-words-and-chars-n-gram/lvl0_lgbm_clean_sub.csv')\n",
    "oofs = pd.read_csv('input/oof-stacking-regime/submission.csv')\n",
    "fast = pd.read_csv('input/pooled-gru-fasttext-6c07c9/submission.csv')\n",
    "gruglo = pd.read_csv(\"input/pooled-gru-glove-with-preprocessing/submission.csv\")\n",
    "tidy = pd.read_csv('input/tidy-xgboost-glmnet-text2vec-lsa/tidy_xgb_glm.csv')\n",
    "ave = pd.read_csv(\"input/toxic-avenger/submission.csv\")\n",
    "best = pd.read_csv('input/toxic-hight-of-blending/hight_of_blending.csv')\n",
    "rkera = pd.read_csv('input/why-a-such-low-score-with-r-and-keras/submission.csv')\n",
    "logreg = pd.read_csv('input/logreg_best/logreg_best.csv')\n",
    "nb_svm = pd.read_csv('input/nb-svm/submission.csv')\n",
    "rf = pd.read_csv('input/rf/RFClassifier.csv')\n",
    "lineg = pd.read_csv('input/linear_regression/submission.csv')\n",
    "nlp_cnn = pd.read_csv('input/nlp_using_cnn/submission.csv')\n",
    "lazy = pd.read_csv('input/lazy/lazy_ensemble_submission.csv')\n",
    "xgb = pd.read_csv('input/subm_xgb_glm/subm_xgb_glm.csv')\n",
    "one_more = pd.read_csv('input/one_more_blend/one_more_blend.csv')\n",
    "vic = pd.read_csv('input/Vic_nn/swa_2_runs_blend.csv')\n",
    "\n",
    "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "b1 = best.copy()\n",
    "col = best.columns\n",
    "\n",
    "col = col.tolist()\n",
    "col.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col:\n",
    "    b1[i] = (2 * fast[i] +\n",
    "             2 * gruglo[i] +\n",
    "             4 * vic[i] +\n",
    "             1 * ave[i] +\n",
    "             2 * supbl[i] +\n",
    "             4 * best[i] +\n",
    "             2 * wordbtch[i] +\n",
    "             2 * lgbm[i] +\n",
    "             1 * tidy[i] +\n",
    "             4 * bilst[i] +\n",
    "             5 * oofs[i] +\n",
    "             4 * corrbl[i] +\n",
    "            25 * one_more[i])\n",
    "    b1[i] = minmax_scale(b1[i])\n",
    "    logreg[i] = minmax_scale(logreg[i])\n",
    "    b1[i] = (b1[i] * 12 - logreg[i]) / 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1.to_csv('submissions/blend_15_with_weights.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit-преобразование моделей до агрегации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordbtch = pd.read_csv('input/wordbatch-fm-ftrl-using-mse-lb-0-9804/lvl0_wordbatch_clean_sub.csv')\n",
    "corrbl = pd.read_csv('input/another-blend-tinkered-by-correlation/corr_blend.csv')\n",
    "grucnn = pd.read_csv('input/bi-gru-cnn-poolings/submission.csv')\n",
    "bilst = pd.read_csv('input/bidirectional-lstm-with-convolution/submission.csv')\n",
    "supbl= pd.read_csv('input/blend-of-blends-1/superblend_1.csv')\n",
    "lgbm = pd.read_csv('input/lgbm-with-words-and-chars-n-gram/lvl0_lgbm_clean_sub.csv')\n",
    "oofs = pd.read_csv('input/oof-stacking-regime/submission.csv')\n",
    "fast = pd.read_csv('input/pooled-gru-fasttext-6c07c9/submission.csv')\n",
    "gruglo = pd.read_csv(\"input/pooled-gru-glove-with-preprocessing/submission.csv\")\n",
    "tidy = pd.read_csv('input/tidy-xgboost-glmnet-text2vec-lsa/tidy_xgb_glm.csv')\n",
    "ave = pd.read_csv(\"input/toxic-avenger/submission.csv\")\n",
    "best = pd.read_csv('input/toxic-hight-of-blending/hight_of_blending.csv')\n",
    "rkera = pd.read_csv('input/why-a-such-low-score-with-r-and-keras/submission.csv')\n",
    "logreg = pd.read_csv('input/logreg_best/logreg_best.csv')\n",
    "nb_svm = pd.read_csv('input/nb-svm/submission.csv')\n",
    "rf = pd.read_csv('input/rf/RFClassifier.csv')\n",
    "\n",
    "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "eps = 1e-5\n",
    "prep = lambda x: logit(np.maximum(np.minimum(x, 1-eps), eps))\n",
    "for label in labels:\n",
    "    wordbtch[label] = prep(wordbtch[label])\n",
    "    corrbl[label] = prep(corrbl[label])\n",
    "    grucnn[label] = prep(grucnn[label])\n",
    "    bilst[label] = prep(bilst[label])\n",
    "    supbl[label] = prep(supbl[label])\n",
    "    lgbm[label] = prep(lgbm[label])\n",
    "    oofs[label] = prep(oofs[label])\n",
    "    fast[label] = prep(fast[label])\n",
    "    gruglo[label] = prep(gruglo[label])\n",
    "    tidy[label] = prep(tidy[label])\n",
    "    ave[label] = prep(ave[label])\n",
    "    best[label] = prep(best[label])\n",
    "    rkera[label] = prep(rkera[label])\n",
    "    logreg[label] = prep(logreg[label])\n",
    "    nb_svm[label] = prep(nb_svm[label])\n",
    "    #rf[label] = minmax_scale(rf[label])\n",
    "\n",
    "b1 = best.copy()\n",
    "col = best.columns\n",
    "\n",
    "col = col.tolist()\n",
    "col.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col:\n",
    "    b1[i] = (3 * fast[i] +\n",
    "             2 * gruglo[i] +\n",
    "             4 * grucnn[i] +\n",
    "             1 * ave[i] +\n",
    "             2 * supbl[i] +\n",
    "             5 * best[i] +\n",
    "             2 * wordbtch[i] +\n",
    "             2 * lgbm[i] +\n",
    "             1 * tidy[i] +\n",
    "             4 * bilst[i] +\n",
    "             5 * oofs[i] +\n",
    "             4 * corrbl[i] +\n",
    "             -0.33 * logreg[i] +\n",
    "             -0 * nb_svm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1.to_csv('submissions/blend_15_with_weights.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
